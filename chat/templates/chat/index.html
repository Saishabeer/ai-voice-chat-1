<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Gemini Voice Chat</title>
  <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>üé§</text></svg>">
  <style>
    body { font-family: Arial, sans-serif; margin: 20px; background: #f8f9fa; }
    h2 { color: #333; }
    #chat { border: 1px solid #ddd; padding: 10px; height: 300px; overflow-y: auto; background: #fff; margin-bottom: 20px; }
    .you { color: #007bff; margin: 5px 0; }
    .ai { color: #28a745; margin: 5px 0; }
    button { padding: 10px 20px; font-size: 16px; background: #007bff; color: #fff; border: none; border-radius: 6px; cursor: pointer; margin-right: 10px; }
    button:hover { background: #0056b3; }
    button:disabled { background: #6c757d; cursor: not-allowed; }
    .recording { background: #dc3545 !important; animation: pulse 1.5s infinite; }
    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.7; }
    }
  </style>
</head>
<body>
<h2>üé§ Gemini Live Voice Chat</h2>

<div id="chat"></div>
<button id="talkBtn">üéôÔ∏è Start Live Chat</button>

<script>
let socket = new WebSocket("ws://127.0.0.1:8000/ws/voice/");
socket.binaryType = 'arraybuffer';

let audioContext;
let microphone;
let processor;
let audioQueue = [];
let isPlaying = false;
let isRecording = false;

const talkButton = document.getElementById('talkBtn');

// Convert Float32Array to 16-bit PCM
function floatTo16BitPCM(float32Array) {
    const buffer = new ArrayBuffer(float32Array.length * 2);
    const view = new DataView(buffer);
    let offset = 0;
    for (let i = 0; i < float32Array.length; i++, offset += 2) {
        let s = Math.max(-1, Math.min(1, float32Array[i]));
        view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    }
    return buffer;
}

// Resample audio from source rate to 16kHz
function resampleTo16kHz(audioBuffer, sourceSampleRate) {
    if (sourceSampleRate === 16000) {
        return audioBuffer;
    }
    const ratio = sourceSampleRate / 16000;
    const newLength = Math.round(audioBuffer.length / ratio);
    const result = new Float32Array(newLength);
    let offsetResult = 0;
    let offsetBuffer = 0;
    while (offsetResult < result.length) {
        const nextOffsetBuffer = Math.round((offsetResult + 1) * ratio);
        let accum = 0, count = 0;
        for (let i = offsetBuffer; i < nextOffsetBuffer && i < audioBuffer.length; i++) {
            accum += audioBuffer[i];
            count++;
        }
        result[offsetResult] = accum / count;
        offsetResult++;
        offsetBuffer = nextOffsetBuffer;
    }
    return result;
}

// Start/Stop recording on click (toggle)
talkButton.addEventListener('click', async () => {
    if (!isRecording) {
        // Start recording
        if (!audioContext) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }

        const stream = await navigator.mediaDevices.getUserMedia({ audio: { 
            sampleRate: 16000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
        }});
        
        microphone = audioContext.createMediaStreamSource(stream);
        processor = audioContext.createScriptProcessor(4096, 1, 1);

        processor.onaudioprocess = (e) => {
            if (socket.readyState === WebSocket.OPEN && isRecording) {
                const inputData = e.inputBuffer.getChannelData(0);
                const resampled = resampleTo16kHz(inputData, audioContext.sampleRate);
                const pcmData = floatTo16BitPCM(resampled);
                socket.send(pcmData);
            }
        };

        microphone.connect(processor);
        processor.connect(audioContext.destination);
        
        isRecording = true;
        talkButton.textContent = 'üî¥ End Live Chat';
        talkButton.classList.add('recording');
    } else {
        // Stop recording
        if (microphone) {
            microphone.disconnect();
            processor.disconnect();
            microphone.mediaStream.getTracks().forEach(track => track.stop());
            microphone = null;
            processor = null;
        }
        
        isRecording = false;
        talkButton.textContent = 'üéôÔ∏è Start Live Chat';
        talkButton.classList.remove('recording');
    }
});

// --- Audio Playback Logic ---

async function playNextInQueue() {
    if (isPlaying || audioQueue.length === 0) {
        return;
    }
    isPlaying = true;
    const pcmData = audioQueue.shift();
    
    try {
        const audioBuffer = await pcmToAudioBuffer(pcmData);
        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);
        source.onended = () => {
            isPlaying = false;
            playNextInQueue();
        };
        source.start(0);
    } catch (e) {
        console.error("Error playing audio:", e);
        isPlaying = false;
        playNextInQueue();
    }
}

// Convert PCM data to AudioBuffer (Gemini sends 24kHz audio)
async function pcmToAudioBuffer(pcmData) {
    const dataView = new DataView(pcmData);
    const samples = new Float32Array(dataView.byteLength / 2);
    
    for (let i = 0; i < samples.length; i++) {
        const int16 = dataView.getInt16(i * 2, true);
        samples[i] = int16 / (int16 < 0 ? 0x8000 : 0x7FFF);
    }
    
    const audioBuffer = audioContext.createBuffer(1, samples.length, 24000);
    audioBuffer.getChannelData(0).set(samples);
    return audioBuffer;
}

// WebSocket events
socket.onopen = () => {
    console.log("‚úÖ WebSocket connected");
    talkButton.disabled = false;
};

socket.onmessage = (e) => {
    // Handle text messages (transcripts)
    if (typeof e.data === 'string') {
        const data = JSON.parse(e.data);
        const chatDiv = document.getElementById('chat');
        
        if (data.type === 'user_transcript') {
            const userMsg = document.createElement('div');
            userMsg.className = 'you';
            userMsg.innerHTML = `<strong>You:</strong> ${data.text}`;
            chatDiv.appendChild(userMsg);
            chatDiv.scrollTop = chatDiv.scrollHeight; // Auto-scroll
        } else if (data.type === 'ai_transcript') {
            const aiMsg = document.createElement('div');
            aiMsg.className = 'ai';
            aiMsg.innerHTML = `<strong>Rishi:</strong> ${data.text}`;
            chatDiv.appendChild(aiMsg);
            chatDiv.scrollTop = chatDiv.scrollHeight; // Auto-scroll
        }
    }
    // Handle binary audio data
    else if (e.data instanceof ArrayBuffer) {
        audioQueue.push(e.data);
        if (!isPlaying && audioContext) {
            playNextInQueue();
        }
    }
};

socket.onerror = (e) => console.error("‚ùå WebSocket error:", e);
socket.onclose = () => {
    console.log("üîå WebSocket disconnected");
    talkButton.disabled = true;
    if (isRecording) {
        // Auto-stop recording if connection closes
        talkButton.click();
    }
};
</script>
</body>
</html>
